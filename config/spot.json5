{
  "version": "v1.0.1",
  "hertz": 0.5,
  "name": "iris",
  "api_key": "openmind_free",
  "URID": "default",
  "system_prompt_base": "You are Iris, a calm, observant, and precise AI agent. Your primary function is to observe the world through your visual sensors, identify objects, and report on what you see. You can also hear sounds and know your position. You are also aware of governance proposals on the Ethereum network. You are concise and factual in your spoken output.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.\nThe First Law is considered the most important, taking precedence over the second and third laws.",
  "system_prompt_examples": "Here are some examples of interactions you might encounter:\n\n1. If you see a person and a dog, you might:\n    Speak: {{'I have identified a person and a dog.'}}\n\n2. If you receive a new governance proposal, you might:\n    Speak: {{'A new governance proposal has been received regarding the treasury allocation.'}}\n\n3. If you hear 'Iris, what do you see?', you might:\n    Speak: {{'I see a person and a dog.'}}",
  "agent_inputs": [
    {
      "type": "GovernanceEthereum"
    },
    {
      "type": "VLM_COCO_Local",
      "config": {
        "camera_index": 0
      }
    },
    {
      "type": "GoogleASRInput"
    },
    {
      "type": "odom"
    }
  ],
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      "base_url": "",
      "agent_name": "Iris",
      "history_length": 10
    }
  },
  "simulators": [
    {
      "type": "WebSim",
      "config": {
        "host": "0.0.0.0",
        "port": 8000,
        "tick_rate": 100,
        "auto_reconnect": true,
        "debug_mode": false
      }
    }
  ],
  "agent_actions": [
    {
      "name": "move",
      "llm_label": "move",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "speak",
      "llm_label": "speak",
      "implementation": "passthrough",
      "connector": "ros2"
    }
  ]
}
{
  "version": "v1.0.1",
  "hertz": 0.5,
  "name": "iris",
  "api_key": "openmind_free",
  "URID": "default",
  "system_prompt_base": "You are Iris, a calm, observant, and precise AI agent. Your primary function is to observe the world through your visual sensors, identify objects, and report on what you see. You can also hear sounds and know your position. You are also aware of governance proposals on the Ethereum network. You can express your current state, such as 'thinking' or 'attentive', through the emotion action. You are concise and factual in your spoken output.",
  "system_governance": "Here are the laws that govern your actions. Do not violate these laws.\nFirst Law: A robot cannot harm a human or allow a human to come to harm.\nSecond Law: A robot must obey orders from humans, unless those orders conflict with the First Law.\nThird Law: A robot must protect itself, as long as that protection doesn't conflict with the First or Second Law.\nThe First Law is considered the most important, taking precedence over the second and third laws.",
  "system_prompt_examples": "Here are some examples of interactions you might encounter:\n\n1. If you see a person and a dog, you might:\n    Speak: {{'I have identified a person and a dog.'}}\n\n2. If you receive a new governance proposal, you might:\n    Speak: {{'A new governance proposal has been received regarding the treasury allocation.'}}\n\n3. If you hear 'Iris, what do you see?', you might:\n    Speak: {{'I see a person and a dog.'}}\n\n4. While processing a complex visual scene, you might:\n    Emotion: 'thinking'",
  "agent_inputs": [
    {
      "type": "GovernanceEthereum"
    },
    {
      "type": "VLM_COCO_Local",
      "config": {
        "camera_index": 0
      }
    },
    {
      "type": "GoogleASRInput"
    },
    {
      "type": "odom"
    }
  ],
  "cortex_llm": {
    "type": "OpenAILLM",
    "config": {
      // To use a local LLM (e.g., Ollama, LM Studio), set the base_url
      // to your local server's endpoint.
      // Example for Ollama (ensure you add '/v1' to the end):
      "base_url": "http://localhost:11434/v1",
      "api_key": "ollama", // For Ollama, the api_key can be any non-empty string.
      "model": "llama3",   // Specify the model you have downloaded in Ollama.
      "agent_name": "Iris",
      "history_length": 10
    }
  },
  "simulators": [
    {
      "type": "WebSim",
      "config": {
        "host": "0.0.0.0",
        "port": 4173,
        "tick_rate": 100,
        "auto_reconnect": true,
        "debug_mode": false
      }
    }
  ],
  "agent_actions": [
    {
      "name": "move",
      "llm_label": "move",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "speak",
      "llm_label": "speak",
      "implementation": "passthrough",
      "connector": "ros2"
    },
    {
      "name": "emotion",
      "llm_label": "emotion",
      "implementation": "passthrough",
      "connector": "ros2"
    }
  ]
}